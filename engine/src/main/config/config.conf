#
# Copyright (C) 2014 Stratio (http://stratio.com)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

#Print streams in each spark iteration
printStreams = false

#Enable stats
statsEnabled = false
	
#Save all actions realized on the platform
auditEnabled = false
	
// Clustering configuration. From this section is possible to configure the High Availability and Sharding capabilities
clustering = {

	// Is the clustering enabled? If true, one of the Decision instances which belongs to the same clusterId will be on charge of manage the cluster status and sync operations
	enabled = false

	// The name of the group. A group is composed by the number of Decision instances configured in the same way in order to offer HA capabilities. To the same group can belongs 1 (not HA) or 2 (HA) Decision instances.
	groupId = "default"

	// List of groups which belongs to the same cluster. It should be the same list in all nodes of the cluster.
	#clusterGroups = ["groupA", "groupB"]

	// Only applies if clustering flag is activated.
	// If true, Decision shards the data automatically into differents topics, named as
	// stratio_decision_data_partition_partitionNumber.
	partitionsEnabled = false

	// List of Kafka topics subscribed by this Decisision instance
	#dataTopics = ["topic_A"]

	// Is failover enabled? It have to be true if you need HA capabilities
	failoverEnabled = false

	failoverPeriod = 300s

	allAckEnabled= false

	ackTimeout = 500 //ms
}

kafka = {
	hosts = ["localhost:9092"]
	connectionTimeout = 10000
	sessionTimeout = 10000
	zookeeperPath = ""
	
	# default replication factor and partitions for internal topics
	replicationFactor = 1
	partitions = 1
}

zookeeper = {
	hosts = ["localhost:2181"]
}
spark = {
	internalHost = "local[6]"
	internalStreamingBatchTime = 2 s
	
	host ="local[6]"
	streamingBatchTime = 2 s

	# additional spark and spark streaming configuration properties for tuning purposes
	# use it really carefully as it can change Decision's behavior dramatically
	tuningProperties = {
		# examples. don't forget to use the quotation marks
		# "spark.streaming.blockInterval" = "200"
		# "spark.streaming.backpressure.enabled" = "true"

	}
}

cassandra = {
	hosts = ["localhost"]
	port = 9042
	# max size of elements in the insert batch.
	# Cassandra does not work properly with batches over 50 elements, so we strongly recommend not to modify this value
	maxBatchSize = 50
	# batchType property values allowed: LOGGED, UNLOGGED
	batchType = "UNLOGGED"
}

mongo = {
	hosts = ["localhost:27017"]
	#username = ""
	#password= ""
	# max size of elements in the bulk insert batch.
	# Mongo does not work properly with batches over 1000 elements, so we strongly recommend not to modify this value
	maxBatchSize = 1000
}

elasticsearch = {
	hosts = ["localhost:9300"]
	clusterName = "elasticsearch"
	# max size of elements in the index batch.
	# The proper max batch size for a bulk indexing in elastic search depends on several factors, but a max size of
	# 1000 elements is a sensible default value
	maxBatchSize = 1000
}

solr = {
	host = "localhost:8983"
	cloud = true
	# If cloud configurations isn enabled, we must provided the zookeeper host that solr cloud is using
	cloudZkHost = "localhost:2181"
	dataDir = "/opt/sds/solr/examples/solr"
}

